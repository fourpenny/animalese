{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec224dc-19a2-467f-9805-15ebc61547d4",
   "metadata": {},
   "source": [
    "## Web Scraper Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ed757c-16d6-4c6c-b5ac-6464fe56a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77990078-5be3-423c-8f25-accb513527a8",
   "metadata": {},
   "source": [
    "Here's where we'll be downloading the dialogue from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99c65a0-cedc-4bf1-9570-726aaad18904",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"https://animalcrossing.fandom.com/wiki/Guide:Cranky_dialogues_(New_Leaf)\", \"https://animalcrossing.fandom.com/wiki/Guide:Peppy_dialogues_(New_Leaf)\",\n",
    "\"https://animalcrossing.fandom.com/wiki/Guide:Player_dialogues\",\"https://animalcrossing.fandom.com/wiki/Guide:Normal_dialogues_(New_Leaf)\",\n",
    "\"https://animalcrossing.fandom.com/wiki/Guide:Lazy_dialogues_(New_Leaf)\", \"https://animalcrossing.fandom.com/wiki/Guide:Sisterly_dialogues_(New_Leaf)\",\n",
    "\"https://animalcrossing.fandom.com/wiki/Guide:Jock_dialogues_(New_Leaf)\", \"https://animalcrossing.fandom.com/wiki/Guide:Smug_dialogues_(New_Leaf)\",\n",
    "\"https://animalcrossing.fandom.com/wiki/Guide:Snooty_dialogues_(New_Leaf)\"]\n",
    "label_list = [\"cranky\",\"peppy\",\"player\",\"normal\",\"lazy\",\"uchi\",\"jock\",\"smug\",\"snooty\"]\n",
    "#the format of these pages is slightly different, so they are their own list\n",
    "p_urls = [\"https://animalcrossing.fandom.com/wiki/Guide:Isabelle_dialogues\",\"https://animalcrossing.fandom.com/wiki/Guide:Resetti_dialogues_(Animal_Crossing)\",\n",
    "\"https://animalcrossing.fandom.com/wiki/Franklin_Dialogue_(GCN)\", \"https://animalcrossing.fandom.com/wiki/Jingle_Dialogue_(GCN)\"]\n",
    "p_labels = [\"isabelle\",\"resetti\",\"franklin\",\"jingle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c3b67a-7de9-441d-9703-27edbba0db1c",
   "metadata": {},
   "source": [
    "Here's where we'll be storing the scraped data, as well as a Regex pattern to help clean the text obtained from each webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9480cffb-788c-4f6c-b527-e721af9d0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = []\n",
    "labels = []\n",
    "pattern = re.compile(\"\\\"([\\S+\\s]+)\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f12c8-ad1a-4879-8ef1-9a578e9ba9f9",
   "metadata": {},
   "source": [
    "Scrape the first group of URLs where the dialogue is contained in list items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1680cae2-6509-43b6-9ccb-0355f258a9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scraping first set of URLs!\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(url_list)):\n",
    "    page = requests.get(url_list[j])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    li = soup.find_all('li')\n",
    "    for item in li:\n",
    "        for i in item.children:\n",
    "            if i.string != None:\n",
    "                text = i.string\n",
    "                #use regex to clean up the string\n",
    "                clean = pattern.match(text)\n",
    "                if clean != None:\n",
    "                    dialogue.append(clean.group(1))\n",
    "                    labels.append(label_list[j])\n",
    "                    \n",
    "print(\"Done scraping first set of URLs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3952e-cf99-42f3-8a09-d26da431d502",
   "metadata": {},
   "source": [
    "Now we scrape the second group of URLs where the dialogue is contained in paragraph tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b70a69-38bf-41ea-9897-6c22f7cb6d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scraping second set of URLs!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(p_urls)):\n",
    "    page = requests.get(p_urls[i])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    p = soup.find_all('p')\n",
    "    for paragraph in p:\n",
    "        if paragraph.string != None:\n",
    "            text = paragraph.string\n",
    "            #use regex to clean up the string\n",
    "            clean = pattern.match(text)\n",
    "            if clean != None:\n",
    "                dialogue.append(clean.group(1))\n",
    "                labels.append(p_labels[i])\n",
    "\n",
    "print(\"Done scraping second set of URLs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b790309-0c4f-4410-b17e-3ef4731b6862",
   "metadata": {},
   "source": [
    "Now we store everything in a dataframe and export it as a .csv file for future use if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc92656-b60f-4912-8c50-82c32f56dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue has been saved!\n"
     ]
    }
   ],
   "source": [
    "df_data = {'dialogue':dialogue, 'labels':labels}\n",
    "dialogue_df = pd.DataFrame(df_data)\n",
    "dialogue_df.to_csv('dialogue.csv', index=False)\n",
    "print(\"Dialogue has been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28c62a-2ce1-45b0-b43b-3792bf03c19c",
   "metadata": {},
   "source": [
    "We can also check out what our dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d82e52-fbd3-410f-aa91-25c492b28790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yo, [player]! Whaddya want? [catchphrase]!</td>\n",
       "      <td>cranky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey, hey, [player]! You got somethin' you wann...</td>\n",
       "      <td>cranky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yo, [player]! What're ya doin'? [catchphrase]?</td>\n",
       "      <td>cranky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whoa, easy now, [player]. Deep breaths... OK. ...</td>\n",
       "      <td>cranky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh. Hey, [player]. Whaddya want from me? [Catc...</td>\n",
       "      <td>cranky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  labels\n",
       "0         Yo, [player]! Whaddya want? [catchphrase]!  cranky\n",
       "1  Hey, hey, [player]! You got somethin' you wann...  cranky\n",
       "2     Yo, [player]! What're ya doin'? [catchphrase]?  cranky\n",
       "3  Whoa, easy now, [player]. Deep breaths... OK. ...  cranky\n",
       "4  Oh. Hey, [player]. Whaddya want from me? [Catc...  cranky"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd9385-a032-4969-b04f-60f95ee19d58",
   "metadata": {},
   "source": [
    "## Text Pre-Processing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "258495f5-52ae-42ab-9306-30c508a70c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39e5cfa3-fb4a-4dbb-9a5d-70d214b94cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 unique characters\n"
     ]
    }
   ],
   "source": [
    "full_text = \"\"\n",
    "\n",
    "for phrase in dialogue_df['dialogue']:\n",
    "    full_text = full_text + ' ' + phrase\n",
    "    \n",
    "full_text = full_text.strip()\n",
    "vocab = sorted(set(full_text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6964e839-59de-4d05-95ad-39a91ab934e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Y' b'o' b',' b' ' b'[' b'p' b'l' b'a' b'y' b'e' b'r' b']' b'!' b' '\n",
      " b'W' b'h' b'a' b'd' b'd' b'y' b'a' b' ' b'w' b'a' b'n' b't' b'?' b' '\n",
      " b'[' b'c' b'a' b't' b'c' b'h' b'p' b'h' b'r' b'a' b's' b'e' b']' b'!'], shape=(42,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "chars = tf.strings.unicode_split(dialogue_df['dialogue'], input_encoding='UTF-8')\n",
    "print(chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf6a3190-155d-4046-ae30-8cd3fbfbdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa11fafe-e8ea-477a-bef8-5d429bb0d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_from_chars(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4580491a-93dc-4891-8e0d-be3addb4e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(full_text, 'UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "350d022e-e502-4e5e-ac1a-67c6ca77240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b9a75c3-c563-4779-a957-66a2f66b53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "178d47c2-7c17-4dfc-b634-62b6ea047fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2d264d1-8bf1-44d4-bd39-ba722f59f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48b83371-3657-487c-8090-dfc62d003ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a3d4906-9981-44a1-9844-444b4ac2470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"Yo, [player]! Whaddya want? [catchphrase]! Hey, hey, [player]! You got somethin' you wanna say to me\"\n",
      "Target: b\"o, [player]! Whaddya want? [catchphrase]! Hey, hey, [player]! You got somethin' you wanna say to me?\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3179422c-18f5-4bf5-82fc-faa234e9c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((64, 64, 100), (64, 64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fd8d8-70ca-45bf-85c0-ec300681c90c",
   "metadata": {},
   "source": [
    "## Creating a RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a4816d7-a535-4957-b0b5-7d96a5c77f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3413d2c8-05ea-44aa-9c7d-2b85874a1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb62a372-b32b-4bda-91a1-be32f00495a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GRUModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "971ce387-3bd1-4b5b-b5d7-cb597fed11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 74) model1: (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions1 = model1(input_example_batch)\n",
    "    print(example_batch_predictions1.shape, \"model1: (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ac33884-5ede-4670-b679-07a0b8c4c165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_rnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  18944     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  75850     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,033,098\n",
      "Trainable params: 4,033,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d53598ef-f24d-461d-9503-5a635861690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32809c95-a6e6-42b4-8fe8-f3fb4a6b4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ea9edcd-79c7-4a6e-a5ba-7c80d87dde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee19fd27-06c9-43c2-97ae-6d0a159ca252",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd80026c-e147-44d7-94c7-e7d3fbe753c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 19s 2s/step - loss: 1.9280\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.8861\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.8548\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.8186\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 1.7836\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 18s 2s/step - loss: 1.7551\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 1.7156\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.6893\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 22s 3s/step - loss: 1.6560\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 23s 3s/step - loss: 1.6232\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 23s 3s/step - loss: 1.5922\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 26s 3s/step - loss: 1.5527\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 24s 3s/step - loss: 1.5280\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.4902\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.4603\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.4289\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.4026\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.3748\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 1.3374\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 22s 3s/step - loss: 1.3089\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 1.2768\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.2421\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.2084\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.1759\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.1399\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 1.1081\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 1.0681\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 1.0274\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.9995\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.9569\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.9264\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.8837\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.8451\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.8044\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.7592\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 21s 3s/step - loss: 0.7219\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.6762\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 19s 2s/step - loss: 0.6410\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 20s 2s/step - loss: 0.5979\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 20s 3s/step - loss: 0.5566\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d15569f1-c904-4202-a1f8-f0282ce6f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cba717b2-0e6c-44d6-9ac6-cc86a48e01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model1 = OneStep(model1, chars_from_ids, ids_from_chars, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120bb27-d474-4b4a-8adb-a05f1df4f8c5",
   "metadata": {},
   "source": [
    "## Predicting using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62a501ec-0cc8-41aa-99af-ab2532427e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applese the for a home right now! Somehow, [catchphrase]. Huh? Are were the ensing in the same personaly today, [catchphrase]? All this from me to hit an the sime! [Catchphrase]! I don't want to be gone of \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.3479282855987549\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['apple'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(200):\n",
    "    next_char, states = one_step_model1.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318405cc-ee74-4383-b6a2-9f09893c45e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
